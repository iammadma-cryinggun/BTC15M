#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Session Memory System - Layer 1 of Three-Layer Architecture

åœ¨ç”Ÿæˆä»»ä½•ä¿¡å·ä¹‹å‰ï¼Œç³»ç»Ÿå°±å·²ç»æœ‰äº†"å…ˆéªŒè§‚ç‚¹"ã€‚
æ‰«æè¿‡å»30+ä¸ªå·²å®Œæˆçš„15åˆ†é’Ÿä¼šè¯ï¼Œè®¡ç®—ï¼š
"å½“è¿‡å»çš„ä¼šè¯çœ‹èµ·æ¥åƒå½“å‰ä¼šè¯æ—¶ï¼Œå“ªè¾¹èµ¢äº†ï¼Ÿ"

å†å²æ•°æ®ä¼šç”Ÿæˆæ–¹å‘æ€§å…ˆéªŒï¼ˆprior biasï¼‰ï¼Œä½œä¸ºå½“å‰ä¼šè¯çš„èµ·ç‚¹ã€‚
"""

import sqlite3
import os
import json
import numpy as np
from datetime import datetime
from collections import deque
from typing import Optional, Tuple, List


class SessionMemory:
    """
    ä¼šè¯è®°å¿†ç³»ç»Ÿï¼šåŸºäºå†å²æ•°æ®çš„å…ˆéªŒæ¦‚ç‡è®¡ç®—

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å­˜å‚¨æ¯ä¸ª15åˆ†é’Ÿä¼šè¯çš„ç‰¹å¾å’Œç»“æœ
    2. åŒ¹é…ç›¸ä¼¼çš„å†å²ä¼šè¯
    3. è®¡ç®—å…ˆéªŒèƒœç‡ï¼ˆprior biasï¼‰
    """

    def __init__(self, db_path: str = None):
        if db_path is None:
            data_dir = os.getenv('DATA_DIR', os.path.dirname(os.path.abspath(__file__)))
            db_path = os.path.join(data_dir, 'btc_15min_auto_trades.db')

        self.db_path = db_path
        self.session_cache = deque(maxlen=100)  # ç¼“å­˜æœ€è¿‘100ä¸ªä¼šè¯ç‰¹å¾
        self.prior_cache = {}  # ç¼“å­˜å…ˆéªŒè®¡ç®—ç»“æœ

        print("[MEMORY] Session Memory System initialized")
        print(f"[MEMORY] Database: {db_path}")

    def _get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path, timeout=30.0)
        conn.row_factory = sqlite3.Row
        return conn

    def extract_session_features(self, market_data: dict) -> dict:
        """
        æå–å½“å‰ä¼šè¯çš„ç‰¹å¾å‘é‡

        ç‰¹å¾åŒ…æ‹¬ï¼š
        1. ä»·æ ¼åŒºé—´ï¼ˆ5ä¸ªbinsï¼‰
        2. æ—¶é—´æ®µï¼ˆ00/15/30/45ï¼‰
        3. RSIåˆå§‹å€¼
        4. Oracleåˆå§‹åˆ†æ•°
        5. 5åˆ†é’Ÿä»·æ ¼è¶‹åŠ¿
        """
        price = market_data.get('price', 0.5)
        rsi = market_data.get('rsi', 50.0)
        oracle_score = market_data.get('oracle_score', 0.0)
        price_history = market_data.get('price_history', [])

        # 1. ä»·æ ¼åŒºé—´ï¼ˆ0.00-0.20, 0.20-0.40, 0.40-0.60, 0.60-0.80, 0.80-1.00ï¼‰
        if price < 0.20:
            price_bin = 0
        elif price < 0.40:
            price_bin = 1
        elif price < 0.60:
            price_bin = 2
        elif price < 0.80:
            price_bin = 3
        else:
            price_bin = 4

        # 2. æ—¶é—´æ®µï¼ˆ0-3ï¼‰
        now = datetime.now()
        time_slot = (now.minute // 15) % 4

        # 3. RSIå½’ä¸€åŒ–ï¼ˆ0-1ï¼‰
        rsi_normalized = rsi / 100.0

        # 4. Oracleå½’ä¸€åŒ–ï¼ˆ-1åˆ°+1ï¼‰
        oracle_normalized = max(-1.0, min(1.0, oracle_score / 10.0))

        # 5. 5åˆ†é’Ÿä»·æ ¼è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰å†å²æ•°æ®ï¼‰
        price_trend = 0.0
        if len(price_history) >= 5:
            recent = price_history[-5:]
            trend = (recent[-1] - recent[0]) / recent[0] if recent[0] > 0 else 0
            price_trend = max(-1.0, min(1.0, trend / 0.1))  # å½’ä¸€åŒ–åˆ°-1åˆ°+1

        features = {
            'price_bin': price_bin,
            'time_slot': time_slot,
            'rsi': rsi_normalized,
            'oracle': oracle_normalized,
            'price_trend': price_trend,
            'timestamp': now.isoformat()
        }

        return features

    def calculate_similarity(self, features1: dict, features2: dict) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªä¼šè¯ç‰¹å¾çš„ç›¸ä¼¼åº¦ï¼ˆæ¬§æ°è·ç¦»ï¼‰

        è¿”å›0-1çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ1=å®Œå…¨ç›¸åŒï¼Œ0=å®Œå…¨ä¸åŒï¼‰
        """
        # ç‰¹å¾æƒé‡ï¼ˆå¯è°ƒæ•´ï¼‰
        weights = {
            'price_bin': 2.0,      # ä»·æ ¼åŒºé—´æœ€é‡è¦
            'time_slot': 1.0,      # æ—¶é—´æ®µæ¬¡ä¹‹
            'rsi': 0.5,            # RSIæƒé‡
            'oracle': 1.5,         # Oracleåˆ†æ•°é‡è¦
            'price_trend': 1.0     # ä»·æ ¼è¶‹åŠ¿
        }

        # è®¡ç®—åŠ æƒæ¬§æ°è·ç¦»
        distance = 0.0
        for key, weight in weights.items():
            if key in features1 and key in features2:
                diff = features1[key] - features2[key]
                distance += weight * (diff ** 2)

        distance = np.sqrt(distance)

        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
        # æœ€å¤§å¯èƒ½è·ç¦»çº¦ä¸º sqrt(2^2 + 1^2 + 0.5^2 + 1.5^2 + 1^2) â‰ˆ 3.0
        similarity = max(0.0, 1.0 - distance / 3.0)

        return similarity

    def get_historical_sessions(self, limit: int = 100) -> List[dict]:
        """ä»æ•°æ®åº“è·å–å†å²ä¼šè¯æ•°æ®"""
        if not os.path.exists(self.db_path):
            print(f"[MEMORY] æ•°æ®åº“ä¸å­˜åœ¨: {self.db_path}")
            return []

        conn = self._get_db_connection()
        cursor = conn.cursor()

        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='positions'")
            if not cursor.fetchone():
                print("[MEMORY] positionsè¡¨ä¸å­˜åœ¨")
                return []

            # æŸ¥è¯¢å·²å…³é—­çš„ä»“ä½
            sql = """
            SELECT
                entry_time,
                side,
                entry_token_price,
                exit_token_price,
                pnl_usd,
                status,
                score,
                oracle_score,
                rsi
            FROM positions
            WHERE status = 'closed'
            ORDER BY entry_time DESC
            LIMIT ?
            """
            cursor.execute(sql, (limit,))
            rows = cursor.fetchall()

            sessions = []
            for row in rows:
                # åˆ¤æ–­èƒœè´Ÿ
                is_win = row['pnl_usd'] and row['pnl_usd'] > 0
                is_long = row['side'] == 'LONG'

                session = {
                    'entry_time': row['entry_time'],
                    'side': row['side'],
                    'entry_price': row['entry_token_price'],
                    'exit_price': row['exit_token_price'],
                    'pnl': row['pnl_usd'] or 0.0,
                    'is_win': is_win,
                    'is_long': is_long,
                    'score': row['score'] or 0.0,
                    'oracle_score': row['oracle_score'] or 0.0,
                    'rsi': row.get('rsi', 50.0)
                }
                sessions.append(session)

            return sessions

        except Exception as e:
            print(f"[MEMORY] è·å–å†å²ä¼šè¯å¤±è´¥: {e}")
            return []
        finally:
            conn.close()

    def calculate_prior_bias(self, current_features: dict, min_sessions: int = 30) -> Tuple[float, dict]:
        """
        è®¡ç®—å…ˆéªŒåå·®ï¼ˆprior biasï¼‰

        æµç¨‹ï¼š
        1. è·å–å†å²ä¼šè¯æ•°æ®
        2. ä¸ºæ¯ä¸ªå†å²ä¼šè¯æå–ç‰¹å¾
        3. è®¡ç®—ä¸å½“å‰ä¼šè¯çš„ç›¸ä¼¼åº¦
        4. é€‰æ‹©æœ€ç›¸ä¼¼çš„min_sessionsä¸ªä¼šè¯
        5. è®¡ç®—è¿™äº›ä¼šè¯çš„YESèƒœç‡
        6. è½¬æ¢ä¸ºå…ˆéªŒåå·®åˆ†æ•°ï¼ˆ-1åˆ°+1ï¼‰

        è¿”å›ï¼š(prior_bias, analysis_dict)
        - prior_bias: -1.0ï¼ˆå¼ºçƒˆå€¾å‘NOï¼‰åˆ°+1.0ï¼ˆå¼ºçƒˆå€¾å‘YESï¼‰
        - analysis_dict: è¯¦ç»†åˆ†ææ•°æ®
        """

        # æ£€æŸ¥ç¼“å­˜
        cache_key = json.dumps(current_features, sort_keys=True)
        if cache_key in self.prior_cache:
            return self.prior_cache[cache_key]

        # è·å–å†å²ä¼šè¯
        historical_sessions = self.get_historical_sessions(limit=200)

        if len(historical_sessions) < min_sessions:
            # æ•°æ®ä¸è¶³ï¼Œè¿”å›ä¸­ç«‹å…ˆéªŒ
            return 0.0, {
                'status': 'insufficient_data',
                'total_sessions': len(historical_sessions),
                'required': min_sessions,
                'message': f'å†å²æ•°æ®ä¸è¶³ï¼ˆ{len(historical_sessions)} < {min_sessions}ï¼‰ï¼Œä½¿ç”¨ä¸­ç«‹å…ˆéªŒ'
            }

        # è®¡ç®—æ¯ä¸ªå†å²ä¼šè¯çš„ç›¸ä¼¼åº¦
        sessions_with_similarity = []
        for session in historical_sessions:
            # ä¸ºå†å²ä¼šè¯é‡å»ºç‰¹å¾
            hist_features = {
                'price_bin': int(session['entry_price'] * 5),  # è¿‘ä¼¼ä»·æ ¼åŒºé—´
                'time_slot': 0,  # å†å²æ•°æ®æ²¡æœ‰ç²¾ç¡®æ—¶é—´ï¼Œè®¾ä¸º0ï¼ˆæƒé‡ä½ï¼Œå½±å“å°ï¼‰
                'rsi': session['rsi'] / 100.0,
                'oracle': max(-1.0, min(1.0, session['oracle_score'] / 10.0)),
                'price_trend': 0.0  # å†å²æ•°æ®æ²¡æœ‰ä»·æ ¼è¶‹åŠ¿ï¼Œè®¾ä¸º0
            }

            similarity = self.calculate_similarity(current_features, hist_features)
            sessions_with_similarity.append({
                'session': session,
                'similarity': similarity
            })

        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œé€‰æ‹©æœ€ç›¸ä¼¼çš„min_sessionsä¸ª
        sessions_with_similarity.sort(key=lambda x: x['similarity'], reverse=True)
        top_sessions = sessions_with_similarity[:min_sessions]

        # ç»Ÿè®¡YES/LONGçš„èƒœç‡
        long_sessions = [s for s in top_sessions if s['session']['is_long']]
        long_wins = sum(1 for s in long_sessions if s['session']['is_win'])
        long_total = len(long_sessions)

        short_sessions = [s for s in top_sessions if not s['session']['is_long']]
        short_wins = sum(1 for s in short_sessions if s['session']['is_win'])
        short_total = len(short_sessions)

        # è®¡ç®—æ–¹å‘æ€§èƒœç‡
        # å¦‚æœLONGèƒœç‡é«˜ â†’ å€¾å‘åšå¤šï¼ˆprior_bias > 0ï¼‰
        # å¦‚æœSHORTèƒœç‡é«˜ â†’ å€¾å‘åšç©ºï¼ˆprior_bias < 0ï¼‰
        if long_total >= 5 and short_total >= 5:
            long_win_rate = long_wins / long_total
            short_win_rate = short_wins / short_total

            # æ–¹å‘åå·®ï¼šLONGèƒœç‡ - SHORTèƒœç‡
            direction_bias = long_win_rate - short_win_rate

            # è½¬æ¢ä¸ºå…ˆéªŒåˆ†æ•°ï¼ˆ-1åˆ°+1ï¼‰
            prior_bias = max(-1.0, min(1.0, direction_bias * 2))  # æ”¾å¤§æ•ˆæœ
        else:
            # æŸä¸ªæ–¹å‘æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨æ€»ä½“èƒœç‡
            total_wins = sum(1 for s in top_sessions if s['session']['is_win'])
            total_win_rate = total_wins / len(top_sessions)
            # å¦‚æœæ€»ä½“èƒœç‡>50%ï¼Œä½¿ç”¨LONGåå€šï¼ˆä¿å®ˆç­–ç•¥ï¼‰
            prior_bias = (total_win_rate - 0.5) * 0.5  # ç¼©å°æ•ˆæœï¼Œæ›´ä¿å®ˆ

        # æ„å»ºåˆ†ææŠ¥å‘Š
        analysis = {
            'status': 'success',
            'total_sessions_analyzed': len(historical_sessions),
            'similar_sessions': min_sessions,
            'long_sessions': long_total,
            'long_wins': long_wins,
            'long_win_rate': long_wins / long_total if long_total > 0 else 0,
            'short_sessions': short_total,
            'short_wins': short_wins,
            'short_win_rate': short_wins / short_total if short_total > 0 else 0,
            'prior_bias': prior_bias,
            'avg_similarity': sum(s['similarity'] for s in top_sessions) / len(top_sessions),
            'top_sessions': top_sessions[:5]  # æœ€ç›¸ä¼¼çš„5ä¸ªä¼šè¯
        }

        # ç¼“å­˜ç»“æœ
        self.prior_cache[cache_key] = (prior_bias, analysis)

        return prior_bias, analysis

    def print_analysis(self, analysis: dict):
        """æ‰“å°å…ˆéªŒåˆ†ææŠ¥å‘Š"""
        if analysis['status'] == 'insufficient_data':
            print(f"ğŸ“Š [MEMORY] {analysis['message']}")
            return

        status = "ğŸŸ¢" if analysis['prior_bias'] > 0.1 else "ğŸ”´" if analysis['prior_bias'] < -0.1 else "âšª"

        print(f"\n{status} [MEMORY] å…ˆéªŒè®°å¿†åˆ†æï¼ˆLayer 1ï¼‰")
        print("=" * 70)
        print(f"  åˆ†ææ ·æœ¬: {analysis['similar_sessions']}ä¸ªç›¸ä¼¼ä¼šè¯ï¼ˆå¹³å‡ç›¸ä¼¼åº¦{analysis['avg_similarity']:.2%}ï¼‰")
        print(f"  LONG: {analysis['long_wins']}/{analysis['long_sessions']} ({analysis['long_win_rate']:.1%})")
        print(f"  SHORT: {analysis['short_wins']}/{analysis['short_sessions']} ({analysis['short_win_rate']:.1%})")
        print(f"  å…ˆéªŒåå·®: {analysis['prior_bias']:+.2f} ", end="")

        if analysis['prior_bias'] > 0.2:
            print("â†’ å€¾å‘åšå¤š (å†å²æ•°æ®æ˜¾ç¤ºLONGèƒœç‡æ›´é«˜)")
        elif analysis['prior_bias'] < -0.2:
            print("â†’ å€¾å‘åšç©º (å†å²æ•°æ®æ˜¾ç¤ºSHORTèƒœç‡æ›´é«˜)")
        else:
            print("â†’ ä¸­ç«‹ (å†å²æ•°æ®æ— æ˜æ˜¾åå‘)")

        print(f"  æœ€ç›¸ä¼¼çš„ä¼šè¯:")
        for i, item in enumerate(analysis['top_sessions'][:3], 1):
            sess = item['session']
            sim = item['similarity']
            result = "âœ…ç›ˆåˆ©" if sess['is_win'] else "âŒäºæŸ"
            print(f"    #{i} {sess['entry_time']} | {sess['side']} @ {sess['entry_price']:.2f} | {result} ${sess['pnl']:+.2f} | ç›¸ä¼¼åº¦{sim:.2%}")

        print("=" * 70)

    def save_session(self, market_data: dict, side: str, entry_price: float, result: dict):
        """
        ä¿å­˜å½“å‰ä¼šè¯çš„ç‰¹å¾åˆ°ç¼“å­˜

        æ³¨æ„ï¼šå®é™…çš„äº¤æ˜“ç»“æœç”±ä¸»ç³»ç»Ÿä¿å­˜åˆ°æ•°æ®åº“
        è¿™ä¸ªæ–¹æ³•åªç”¨äºæ›´æ–°å†…å­˜ç¼“å­˜
        """
        features = self.extract_session_features(market_data)
        features['side'] = side
        features['entry_price'] = entry_price
        features['result'] = result

        self.session_cache.append(features)

        # æ¸…é™¤å…ˆéªŒç¼“å­˜ï¼ˆå› ä¸ºæ–°æ•°æ®å·²æ·»åŠ ï¼‰
        self.prior_cache.clear()


if __name__ == "__main__":
    # æµ‹è¯•Session Memoryç³»ç»Ÿ
    memory = SessionMemory()

    # æ¨¡æ‹Ÿå½“å‰å¸‚åœºæ•°æ®
    current_market = {
        'price': 0.35,
        'rsi': 45.0,
        'oracle_score': 3.5,
        'price_history': [0.32, 0.33, 0.34, 0.35, 0.36]
    }

    features = memory.extract_session_features(current_market)
    print("\nå½“å‰ä¼šè¯ç‰¹å¾:")
    print(json.dumps(features, indent=2))

    prior_bias, analysis = memory.calculate_prior_bias(features)
    memory.print_analysis(analysis)

    print(f"\nå…ˆéªŒåå·®åˆ†æ•°: {prior_bias:+.2f}")
    print("ä½¿ç”¨æ–¹å¼: signal_score += prior_bias * 2.0  (è°ƒæ•´æƒé‡)")
