#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Session Memory System - Layer 1 of Three-Layer Architecture

åœ¨ç”Ÿæˆä»»ä½•ä¿¡å·ä¹‹å‰ï¼Œç³»ç»Ÿå°±å·²ç»æœ‰äº†"å…ˆéªŒè§‚ç‚¹"ã€‚
æ‰«æè¿‡å»30+ä¸ªå·²å®Œæˆçš„15åˆ†é’Ÿä¼šè¯ï¼Œè®¡ç®—ï¼š
"å½“è¿‡å»çš„ä¼šè¯çœ‹èµ·æ¥åƒå½“å‰ä¼šè¯æ—¶ï¼Œå“ªè¾¹èµ¢äº†ï¼Ÿ"

å†å²æ•°æ®ä¼šç”Ÿæˆæ–¹å‘æ€§å…ˆéªŒï¼ˆprior biasï¼‰ï¼Œä½œä¸ºå½“å‰ä¼šè¯çš„èµ·ç‚¹ã€‚
"""

import sqlite3
import os
import json
import numpy as np
from datetime import datetime
from collections import deque
from typing import Optional, Tuple, List


class SessionMemory:
    """
    ä¼šè¯è®°å¿†ç³»ç»Ÿï¼šåŸºäºå†å²æ•°æ®çš„å…ˆéªŒæ¦‚ç‡è®¡ç®—

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. å­˜å‚¨æ¯ä¸ª15åˆ†é’Ÿä¼šè¯çš„ç‰¹å¾å’Œç»“æœ
    2. åŒ¹é…ç›¸ä¼¼çš„å†å²ä¼šè¯
    3. è®¡ç®—å…ˆéªŒèƒœç‡ï¼ˆprior biasï¼‰
    """

    def __init__(self, db_path: str = None):
        if db_path is None:
            data_dir = os.getenv('DATA_DIR', os.path.dirname(os.path.abspath(__file__)))
            db_path = os.path.join(data_dir, 'btc_15min_auto_trades.db')

        self.db_path = db_path
        self.session_cache = deque(maxlen=100)  # ç¼“å­˜æœ€è¿‘100ä¸ªä¼šè¯ç‰¹å¾
        self.prior_cache = {}  # ç¼“å­˜å…ˆéªŒè®¡ç®—ç»“æœ

        # Sessioné¢„åŠ è½½ç¼“å­˜
        self.current_session_id = None  # å½“å‰session ID (æ ¼å¼: YYYYMMDD_HHMM)
        self.current_session_bias = 0.0  # å½“å‰sessionçš„prior_bias
        self.current_session_analysis = {}  # å½“å‰sessionçš„åˆ†æè¯¦æƒ…

        print("[MEMORY] Session Memory System initialized")
        print(f"[MEMORY] Database: {db_path}")

    def _get_db_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥"""
        conn = sqlite3.connect(self.db_path, timeout=30.0)
        conn.row_factory = sqlite3.Row
        return conn

    def extract_session_features(self, market_data: dict) -> dict:
        """
        æå–å½“å‰ä¼šè¯çš„ç‰¹å¾å‘é‡

        ç‰¹å¾åŒ…æ‹¬ï¼ˆçƒ­å¿ƒå“¥åŸç‰ˆè¦æ±‚ï¼‰ï¼š
        1. ä»·æ ¼åŒºé—´ï¼ˆ5ä¸ªbinsï¼‰
        2. æ—¶é—´æ®µï¼ˆ00/15/30/45ï¼‰
        3. RSIåˆå§‹å€¼
        4. CVDå¼ºåº¦ï¼ˆæ›¿ä»£Oracleåˆ†æ•°ï¼‰
        5. 5åˆ†é’Ÿä»·æ ¼è¶‹åŠ¿
        6. æ³¢åŠ¨ç‡ï¼ˆVolatilityï¼‰â† æ–°å¢
        """
        price = market_data.get('price', 0.5)
        rsi = market_data.get('rsi', 50.0)
        oracle = market_data.get('oracle', {})
        cvd_5m = oracle.get('cvd_5m', 0.0)  # ä½¿ç”¨CVDæ›¿ä»£oracle_score
        price_history = market_data.get('price_history', [])

        # 1. ä»·æ ¼åŒºé—´ï¼ˆ0.00-0.20, 0.20-0.40, 0.40-0.60, 0.60-0.80, 0.80-1.00ï¼‰
        if price < 0.20:
            price_bin = 0
        elif price < 0.40:
            price_bin = 1
        elif price < 0.60:
            price_bin = 2
        elif price < 0.80:
            price_bin = 3
        else:
            price_bin = 4

        # 2. æ—¶é—´æ®µï¼ˆ0-3ï¼‰
        now = datetime.now()
        time_slot = (now.minute // 15) % 4

        # 3. RSIå½’ä¸€åŒ–ï¼ˆ0-1ï¼‰
        rsi_normalized = rsi / 100.0

        # 4. CVDå½’ä¸€åŒ–ï¼ˆ-1åˆ°+1ï¼‰ï¼Œä½¿ç”¨5åˆ†é’ŸCVDèŒƒå›´[-150000, +150000]
        cvd_normalized = max(-1.0, min(1.0, cvd_5m / 150000.0))

        # 5. 5åˆ†é’Ÿä»·æ ¼è¶‹åŠ¿ï¼ˆå¦‚æœæœ‰å†å²æ•°æ®ï¼‰
        price_trend = 0.0
        if len(price_history) >= 5:
            recent = price_history[-5:]
            trend = (recent[-1] - recent[0]) / recent[0] if recent[0] > 0 else 0
            price_trend = max(-1.0, min(1.0, trend / 0.1))  # å½’ä¸€åŒ–åˆ°-1åˆ°+1

        # 6. æ³¢åŠ¨ç‡ï¼ˆVolatilityï¼‰â† æ–°å¢ç‰¹å¾
        # è®¡ç®—ä»·æ ¼å†å²çš„æ ‡å‡†å·®ä½œä¸ºæ³¢åŠ¨ç‡æŒ‡æ ‡
        volatility = 0.0
        if len(price_history) >= 10:
            # ä½¿ç”¨æœ€è¿‘10ä¸ªä»·æ ¼ç‚¹è®¡ç®—æ³¢åŠ¨ç‡
            import statistics
            prices = price_history[-10:]
            # æ ‡å‡†å·®å½’ä¸€åŒ–ï¼šé™¤ä»¥å¹³å‡ä»·æ ¼ï¼Œå¾—åˆ°ç›¸å¯¹æ³¢åŠ¨ç‡
            std_dev = statistics.stdev(prices)
            avg_price = statistics.mean(prices)
            volatility = std_dev / avg_price if avg_price > 0 else 0.0
            # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´ï¼ˆå‡è®¾æ³¢åŠ¨ç‡èŒƒå›´0-0.3ï¼‰
            volatility = min(1.0, volatility / 0.3)

        features = {
            'price_bin': price_bin,
            'time_slot': time_slot,
            'rsi': rsi_normalized,
            'cvd': cvd_normalized,
            'price_trend': price_trend,
            'volatility': volatility,  # â† æ–°å¢ï¼šæ³¢åŠ¨ç‡ç‰¹å¾
            'timestamp': now.isoformat()
        }

        return features

    def calculate_similarity(self, features1: dict, features2: dict) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªä¼šè¯ç‰¹å¾çš„ç›¸ä¼¼åº¦ï¼ˆæ¬§æ°è·ç¦»ï¼‰

        è¿”å›0-1çš„ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ1=å®Œå…¨ç›¸åŒï¼Œ0=å®Œå…¨ä¸åŒï¼‰
        """
        # ç‰¹å¾æƒé‡ï¼ˆå¯è°ƒæ•´ï¼‰
        weights = {
            'price_bin': 2.0,      # ä»·æ ¼åŒºé—´æœ€é‡è¦
            'time_slot': 1.0,      # æ—¶é—´æ®µæ¬¡ä¹‹
            'rsi': 0.5,            # RSIæƒé‡
            'cvd': 1.5,            # CVDå¼ºåº¦é‡è¦
            'price_trend': 1.0,    # ä»·æ ¼è¶‹åŠ¿
            'volatility': 1.2      # æ³¢åŠ¨ç‡ï¼ˆæ–°å¢ï¼‰
        }

        # è®¡ç®—åŠ æƒæ¬§æ°è·ç¦»
        distance = 0.0
        for key, weight in weights.items():
            if key in features1 and key in features2:
                diff = features1[key] - features2[key]
                distance += weight * (diff ** 2)

        distance = np.sqrt(distance)

        # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼ˆè·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜ï¼‰
        # æœ€å¤§å¯èƒ½è·ç¦»çº¦ä¸º sqrt(2^2 + 1^2 + 0.5^2 + 1.5^2 + 1^2) â‰ˆ 3.0
        similarity = max(0.0, 1.0 - distance / 3.0)

        return similarity

    def get_historical_sessions(self, limit: int = 100) -> List[dict]:
        """ä»æ•°æ®åº“è·å–å†å²ä¼šè¯æ•°æ®"""
        if not os.path.exists(self.db_path):
            print(f"[MEMORY] æ•°æ®åº“ä¸å­˜åœ¨: {self.db_path}")
            return []

        conn = self._get_db_connection()
        cursor = conn.cursor()

        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='positions'")
            if not cursor.fetchone():
                print("[MEMORY] positionsè¡¨ä¸å­˜åœ¨")
                return []

            # æŸ¥è¯¢å·²å…³é—­çš„ä»“ä½ï¼ˆåŒ…å«å®Œæ•´æŒ‡æ ‡æ•°æ®ï¼‰
            sql = """
            SELECT
                entry_time,
                side,
                entry_token_price,
                exit_token_price,
                pnl_usd,
                status,
                score,
                rsi,
                vwap,
                cvd_5m,
                cvd_1m,
                prior_bias,
                defense_multiplier,
                minutes_to_expiry
            FROM positions
            WHERE status = 'closed'
            ORDER BY entry_time DESC
            LIMIT ?
            """
            cursor.execute(sql, (limit,))
            rows = cursor.fetchall()

            sessions = []
            for row in rows:
                # åˆ¤æ–­èƒœè´Ÿ
                is_win = row['pnl_usd'] and row['pnl_usd'] > 0
                is_long = row['side'] == 'LONG'

                # ä»æ•°æ®åº“è¯»å–çœŸå®æŒ‡æ ‡ï¼ˆç”¨äºç›¸ä¼¼åº¦åŒ¹é…ï¼‰
                cvd_5m = row['cvd_5m'] or 0.0
                cvd_1m = row['cvd_1m'] or 0.0
                cvd_combined = cvd_5m * 0.7 + cvd_1m * 0.3  # ä¸é˜²å¾¡å±‚ä¸€è‡´

                session = {
                    'entry_time': row['entry_time'],
                    'side': row['side'],
                    'entry_price': row['entry_token_price'],
                    'exit_price': row['exit_token_price'],
                    'pnl': row['pnl_usd'] or 0.0,
                    'is_win': is_win,
                    'is_long': is_long,
                    'score': row['score'] or 0.0,
                    'cvd': cvd_combined,  # çœŸå®CVDæ•°æ®
                    'rsi': row['rsi'] or 50.0,  # çœŸå®RSIæ•°æ®
                    'vwap': row['vwap'] or 0.0,  # çœŸå®VWAPæ•°æ®
                    'prior_bias': row['prior_bias'] or 0.0,  # çœŸå®å…ˆéªŒåå·®
                    'defense_multiplier': row['defense_multiplier'] or 1.0,  # çœŸå®é˜²å¾¡ä¹˜æ•°
                    'minutes_to_expiry': row['minutes_to_expiry'] or 0,  # Sessionå‰©ä½™åˆ†é’Ÿæ•°
                }
                sessions.append(session)

            return sessions

        except Exception as e:
            print(f"[MEMORY] è·å–å†å²ä¼šè¯å¤±è´¥: {e}")
            return []
        finally:
            conn.close()

    def calculate_prior_bias(self, current_features: dict, min_sessions: int = 30) -> Tuple[float, dict]:
        """
        è®¡ç®—å…ˆéªŒåå·®ï¼ˆprior biasï¼‰

        æµç¨‹ï¼š
        1. è·å–å†å²ä¼šè¯æ•°æ®
        2. ä¸ºæ¯ä¸ªå†å²ä¼šè¯æå–ç‰¹å¾
        3. è®¡ç®—ä¸å½“å‰ä¼šè¯çš„ç›¸ä¼¼åº¦
        4. é€‰æ‹©æœ€ç›¸ä¼¼çš„min_sessionsä¸ªä¼šè¯
        5. è®¡ç®—è¿™äº›ä¼šè¯çš„YESèƒœç‡
        6. è½¬æ¢ä¸ºå…ˆéªŒåå·®åˆ†æ•°ï¼ˆ-1åˆ°+1ï¼‰

        è¿”å›ï¼š(prior_bias, analysis_dict)
        - prior_bias: -1.0ï¼ˆå¼ºçƒˆå€¾å‘NOï¼‰åˆ°+1.0ï¼ˆå¼ºçƒˆå€¾å‘YESï¼‰
        - analysis_dict: è¯¦ç»†åˆ†ææ•°æ®
        """

        # æ£€æŸ¥ç¼“å­˜
        cache_key = json.dumps(current_features, sort_keys=True)
        if cache_key in self.prior_cache:
            return self.prior_cache[cache_key]

        # è·å–å†å²ä¼šè¯
        historical_sessions = self.get_historical_sessions(limit=200)

        if len(historical_sessions) < min_sessions:
            # æ•°æ®ä¸è¶³ï¼Œè¿”å›ä¸­ç«‹å…ˆéªŒ
            return 0.0, {
                'status': 'insufficient_data',
                'total_sessions': len(historical_sessions),
                'required': min_sessions,
                'message': f'å†å²æ•°æ®ä¸è¶³ï¼ˆ{len(historical_sessions)} < {min_sessions}ï¼‰ï¼Œä½¿ç”¨ä¸­ç«‹å…ˆéªŒ'
            }

        # è®¡ç®—æ¯ä¸ªå†å²ä¼šè¯çš„ç›¸ä¼¼åº¦
        sessions_with_similarity = []
        for session in historical_sessions:
            # ä¸ºå†å²ä¼šè¯é‡å»ºç‰¹å¾
            hist_features = {
                'price_bin': int(session['entry_price'] * 5),  # è¿‘ä¼¼ä»·æ ¼åŒºé—´
                'time_slot': 0,  # å†å²æ•°æ®æ²¡æœ‰ç²¾ç¡®æ—¶é—´ï¼Œè®¾ä¸º0ï¼ˆæƒé‡ä½ï¼Œå½±å“å°ï¼‰
                'rsi': session['rsi'] / 100.0,
                'cvd': max(-1.0, min(1.0, session['cvd'] / 150000.0)),
                'price_trend': 0.0,  # å†å²æ•°æ®æ²¡æœ‰ä»·æ ¼è¶‹åŠ¿ï¼Œè®¾ä¸º0
                'volatility': 0.5  # å†å²æ•°æ®æ²¡æœ‰æ³¢åŠ¨ç‡ï¼Œè®¾ä¸ºä¸­æ€§å€¼ï¼ˆæƒé‡å½±å“å°ï¼‰
            }

            similarity = self.calculate_similarity(current_features, hist_features)
            sessions_with_similarity.append({
                'session': session,
                'similarity': similarity
            })

        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œé€‰æ‹©æœ€ç›¸ä¼¼çš„min_sessionsä¸ª
        sessions_with_similarity.sort(key=lambda x: x['similarity'], reverse=True)
        top_sessions = sessions_with_similarity[:min_sessions]

        # ğŸ• Layer 1ä¼˜åŒ–ï¼šæœ€å6åˆ†é’ŸåŠ æƒä¼˜å…ˆ
        # å›æµ‹æ•°æ®æ˜¾ç¤ºï¼šsessionæœ€å6åˆ†é’ŸæŒ‡æ ‡æœ€å¯é ï¼Œç»™äºˆæ›´é«˜æƒé‡
        def get_time_weight(minutes_to_expiry: int) -> float:
            """æ ¹æ®sessionå‰©ä½™æ—¶é—´è¿”å›æƒé‡ï¼ˆæœ€å6åˆ†é’Ÿä¼˜å…ˆï¼‰"""
            if minutes_to_expiry <= 6:
                return 2.0  # é»„é‡‘6åˆ†é’Ÿï¼šæœ€é«˜æƒé‡
            elif minutes_to_expiry <= 9:
                return 1.5  # 7-9åˆ†é’Ÿï¼šä¸­ç­‰æƒé‡
            else:
                return 1.0  # 10-14åˆ†é’Ÿï¼šæ­£å¸¸æƒé‡

        # ç»Ÿè®¡LONG/SHORTçš„åŠ æƒèƒœç‡
        long_weighted_wins = 0.0
        long_total_weight = 0.0
        short_weighted_wins = 0.0
        short_total_weight = 0.0

        for item in top_sessions:
            session = item['session']
            weight = get_time_weight(session.get('minutes_to_expiry', 0))

            if session['is_long']:
                long_total_weight += weight
                if session['is_win']:
                    long_weighted_wins += weight
            else:
                short_total_weight += weight
                if session['is_win']:
                    short_weighted_wins += weight

        # è®¡ç®—åŠ æƒæ–¹å‘æ€§èƒœç‡
        # å¦‚æœLONGèƒœç‡é«˜ â†’ å€¾å‘åšå¤šï¼ˆprior_bias > 0ï¼‰
        # å¦‚æœSHORTèƒœç‡é«˜ â†’ å€¾å‘åšç©ºï¼ˆprior_bias < 0ï¼‰
        if long_total_weight >= 5.0 and short_total_weight >= 5.0:
            long_win_rate = long_weighted_wins / long_total_weight
            short_win_rate = short_weighted_wins / short_total_weight

            # æ–¹å‘åå·®ï¼šLONGèƒœç‡ - SHORTèƒœç‡
            direction_bias = long_win_rate - short_win_rate

            # è½¬æ¢ä¸ºå…ˆéªŒåˆ†æ•°ï¼ˆ-1åˆ°+1ï¼‰
            prior_bias = max(-1.0, min(1.0, direction_bias * 2))  # æ”¾å¤§æ•ˆæœ
        else:
            # æŸä¸ªæ–¹å‘æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨æ€»ä½“åŠ æƒèƒœç‡
            total_weighted_wins = long_weighted_wins + short_weighted_wins
            total_weight = long_total_weight + short_total_weight
            total_win_rate = total_weighted_wins / total_weight if total_weight > 0 else 0.5
            # å¦‚æœæ€»ä½“èƒœç‡>50%ï¼Œä½¿ç”¨LONGåå€šï¼ˆä¿å®ˆç­–ç•¥ï¼‰
            prior_bias = (total_win_rate - 0.5) * 0.5  # ç¼©å°æ•ˆæœï¼Œæ›´ä¿å®ˆ

        # ç»Ÿè®¡åŸå§‹æ•°é‡ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        long_count = sum(1 for s in top_sessions if s['session']['is_long'])
        short_count = sum(1 for s in top_sessions if not s['session']['is_long'])

        # ç»Ÿè®¡æœ€å6åˆ†é’Ÿçš„äº¤æ˜“æ•°é‡
        last_6min_sessions = [s for s in top_sessions if s['session'].get('minutes_to_expiry', 0) <= 6]
        last_6min_count = len(last_6min_sessions)

        # æ„å»ºåˆ†ææŠ¥å‘Š
        analysis = {
            'status': 'success',
            'total_sessions_analyzed': len(historical_sessions),
            'similar_sessions': min_sessions,
            'long_sessions': long_count,
            'long_wins': sum(1 for s in top_sessions if s['session']['is_long'] and s['session']['is_win']),
            'long_win_rate': long_weighted_wins / long_total_weight if long_total_weight > 0 else 0,
            'short_sessions': short_count,
            'short_wins': sum(1 for s in top_sessions if not s['session']['is_long'] and s['session']['is_win']),
            'short_win_rate': short_weighted_wins / short_total_weight if short_total_weight > 0 else 0,
            'prior_bias': prior_bias,
            'avg_similarity': sum(s['similarity'] for s in top_sessions) / len(top_sessions),
            'last_6min_count': last_6min_count,  # æœ€å6åˆ†é’Ÿçš„äº¤æ˜“æ•°é‡
            'top_sessions': top_sessions[:5]  # æœ€ç›¸ä¼¼çš„5ä¸ªä¼šè¯
        }

        # ç¼“å­˜ç»“æœ
        self.prior_cache[cache_key] = (prior_bias, analysis)

        return prior_bias, analysis

    def preload_session_bias(self, price: float, rsi: float, oracle: dict, price_history: list = None) -> bool:
        """
        åœ¨sessionå¼€å§‹æ—¶é¢„åŠ è½½prior_bias

        åœ¨æ¯ä¸ª15åˆ†é’Ÿsessionå¼€å§‹æ—¶è°ƒç”¨ï¼Œè®¡ç®—å¹¶ç¼“å­˜æ•´ä¸ªsessionçš„å…ˆéªŒbiasã€‚
        ä¹‹ååŒä¸€sessionçš„ä¿¡å·ç”Ÿæˆç›´æ¥ä½¿ç”¨ç¼“å­˜å€¼ï¼Œæ— éœ€é‡æ–°è®¡ç®—ã€‚

        Args:
            price: å½“å‰ä»·æ ¼
            rsi: å½“å‰RSI
            oracle: Oracleæ•°æ®å­—å…¸ï¼ˆåŒ…å«cvd_5mç­‰ï¼‰
            price_history: ä»·æ ¼å†å²åˆ—è¡¨

        Returns:
            bool: æ˜¯å¦æˆåŠŸé¢„åŠ è½½
        """
        try:
            # è®¡ç®—å½“å‰session ID
            now = datetime.now()
            session_id = now.strftime('%Y%m%d_%H%M')

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„session
            if self.current_session_id == session_id:
                # åŒä¸€ä¸ªsessionï¼Œå·²é¢„åŠ è½½è¿‡
                return True

            # æå–ç‰¹å¾
            market_features = {
                'price': price,
                'rsi': rsi,
                'oracle': oracle or {},
                'price_history': price_history or []
            }

            features = self.extract_session_features(market_features)

            # è®¡ç®—prior_bias
            prior_bias, analysis = self.calculate_prior_bias(features)

            # ç¼“å­˜sessionçº§åˆ«çš„ç»“æœ
            self.current_session_id = session_id
            self.current_session_bias = prior_bias
            self.current_session_analysis = analysis

            # æ‰“å°é¢„åŠ è½½ç»“æœ
            self.print_preload_result(analysis)

            return True

        except Exception as e:
            print(f"[MEMORY ERROR] é¢„åŠ è½½å¤±è´¥: {e}")
            # ä½¿ç”¨ä¸­ç«‹å…ˆéªŒ
            self.current_session_bias = 0.0
            self.current_session_analysis = {'status': 'error', 'error': str(e)}
            return False

    def get_cached_bias(self) -> float:
        """
        è·å–å½“å‰sessionç¼“å­˜çš„prior_bias

        åœ¨ä¿¡å·ç”Ÿæˆæ—¶è°ƒç”¨ï¼Œå¿«é€Ÿè¿”å›é¢„è®¡ç®—çš„biaså€¼ã€‚
        """
        return self.current_session_bias

    def get_cached_analysis(self) -> dict:
        """è·å–å½“å‰sessionç¼“å­˜çš„analysisè¯¦æƒ…"""
        return self.current_session_analysis

    def print_preload_result(self, analysis: dict):
        """æ‰“å°é¢„åŠ è½½ç»“æœ"""
        if analysis.get('status') == 'insufficient_data':
            print(f"âšª [MEMORY-L1] Sessioné¢„åŠ è½½: å†å²æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨ä¸­ç«‹å…ˆéªŒ (0.00)")
            return

        bias = analysis.get('prior_bias', 0.0)
        emoji = "ğŸŸ¢" if bias > 0.2 else "ğŸ”´" if bias < -0.2 else "âšª"

        long_wr = analysis.get('long_win_rate', 0.0)
        short_wr = analysis.get('short_win_rate', 0.0)
        similar = analysis.get('similar_sessions', 0)
        last_6min = analysis.get('last_6min_count', 0)

        print(f"{emoji} [MEMORY-L1] Sessioné¢„åŠ è½½å®Œæˆ")
        print(f"     åŸºäºè¿‡å»{similar}ä¸ªç›¸ä¼¼session(å«{last_6min}ä¸ªé»„é‡‘6åˆ†é’Ÿ)")
        print(f"     åŠ æƒèƒœç‡: LONG={long_wr:.1%} SHORT={short_wr:.1%} (æœ€å6åˆ†é’Ÿæƒé‡2x)")
        print(f"     å…ˆéªŒbias: {bias:+.2f} {'(å€¾å‘åšå¤š)' if bias > 0.2 else '(å€¾å‘åšç©º)' if bias < -0.2 else '(ä¸­ç«‹)'}")

    def print_analysis(self, analysis: dict):
        """æ‰“å°å…ˆéªŒåˆ†ææŠ¥å‘Š"""
        if analysis['status'] == 'insufficient_data':
            print(f"ğŸ“Š [MEMORY] {analysis['message']}")
            return

        status = "ğŸŸ¢" if analysis['prior_bias'] > 0.1 else "ğŸ”´" if analysis['prior_bias'] < -0.1 else "âšª"

        print(f"\n{status} [MEMORY] å…ˆéªŒè®°å¿†åˆ†æï¼ˆLayer 1ï¼‰")
        print("=" * 70)
        print(f"  åˆ†ææ ·æœ¬: {analysis['similar_sessions']}ä¸ªç›¸ä¼¼ä¼šè¯ï¼ˆå¹³å‡ç›¸ä¼¼åº¦{analysis['avg_similarity']:.2%}ï¼‰")
        print(f"  ğŸ• æ—¶é—´åŠ æƒ: {analysis['last_6min_count']}ä¸ªé»„é‡‘6åˆ†é’Ÿä¼šè¯(æƒé‡2x) + {analysis['similar_sessions'] - analysis['last_6min_count']}ä¸ªå…¶ä»–ä¼šè¯")
        print(f"  LONG: {analysis['long_wins']}/{analysis['long_sessions']} ({analysis['long_win_rate']:.1%} åŠ æƒ)")
        print(f"  SHORT: {analysis['short_wins']}/{analysis['short_sessions']} ({analysis['short_win_rate']:.1%} åŠ æƒ)")
        print(f"  å…ˆéªŒåå·®: {analysis['prior_bias']:+.2f} ", end="")

        if analysis['prior_bias'] > 0.2:
            print("â†’ å€¾å‘åšå¤š (å†å²æ•°æ®æ˜¾ç¤ºLONGèƒœç‡æ›´é«˜)")
        elif analysis['prior_bias'] < -0.2:
            print("â†’ å€¾å‘åšç©º (å†å²æ•°æ®æ˜¾ç¤ºSHORTèƒœç‡æ›´é«˜)")
        else:
            print("â†’ ä¸­ç«‹ (å†å²æ•°æ®æ— æ˜æ˜¾åå‘)")

        print(f"  æœ€ç›¸ä¼¼çš„ä¼šè¯:")
        for i, item in enumerate(analysis['top_sessions'][:3], 1):
            sess = item['session']
            sim = item['similarity']
            result = "âœ…ç›ˆåˆ©" if sess['is_win'] else "âŒäºæŸ"
            minutes = sess.get('minutes_to_expiry', 0)
            weight_icon = "â­" if minutes <= 6 else ""
            print(f"    #{i} {sess['entry_time']} | {sess['side']} @ {sess['entry_price']:.2f} | {result} ${sess['pnl']:+.2f} | ç›¸ä¼¼åº¦{sim:.2%} {weight_icon}")

        print("=" * 70)

    def save_session(self, market_data: dict, side: str, entry_price: float, result: dict):
        """
        ä¿å­˜å½“å‰ä¼šè¯çš„ç‰¹å¾åˆ°ç¼“å­˜

        æ³¨æ„ï¼šå®é™…çš„äº¤æ˜“ç»“æœç”±ä¸»ç³»ç»Ÿä¿å­˜åˆ°æ•°æ®åº“
        è¿™ä¸ªæ–¹æ³•åªç”¨äºæ›´æ–°å†…å­˜ç¼“å­˜
        """
        features = self.extract_session_features(market_data)
        features['side'] = side
        features['entry_price'] = entry_price
        features['result'] = result

        self.session_cache.append(features)

        # æ¸…é™¤å…ˆéªŒç¼“å­˜ï¼ˆå› ä¸ºæ–°æ•°æ®å·²æ·»åŠ ï¼‰
        self.prior_cache.clear()


if __name__ == "__main__":
    # æµ‹è¯•Session Memoryç³»ç»Ÿ
    memory = SessionMemory()

    # æ¨¡æ‹Ÿå½“å‰å¸‚åœºæ•°æ®
    current_market = {
        'price': 0.35,
        'rsi': 45.0,
        'oracle_score': 3.5,
        'price_history': [0.32, 0.33, 0.34, 0.35, 0.36]
    }

    features = memory.extract_session_features(current_market)
    print("\nå½“å‰ä¼šè¯ç‰¹å¾:")
    print(json.dumps(features, indent=2))

    prior_bias, analysis = memory.calculate_prior_bias(features)
    memory.print_analysis(analysis)

    print(f"\nå…ˆéªŒåå·®åˆ†æ•°: {prior_bias:+.2f}")
    print("ä½¿ç”¨æ–¹å¼: signal_score += prior_bias * 2.0  (è°ƒæ•´æƒé‡)")
